{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1WpKGb4mShUJ"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "\n",
        "import awkward as ak\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "from utils import get_file_list, import_audio_dataset, encode_file_names, \\\n",
        "    pad_awkward_array, audio_tokenizer, downsample_tensor, get_file_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aQYygM3TAtU",
        "outputId": "c797dd67-7c7f-4b0f-d941-5f1a65141b25"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-03-19 19:47:13.849\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mimport_audio_dataset\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mLoading 2452 files to list...\u001b[0m\n",
            "  0%|          | 0/2452 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2452/2452 [00:09<00:00, 263.90it/s]\n",
            "\u001b[32m2024-03-19 19:47:23.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mimport_audio_dataset\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1mLoading 2452 files to awkward array...\u001b[0m\n",
            "100%|██████████| 2452/2452 [06:17<00:00,  6.50it/s]\n",
            "\u001b[32m2024-03-19 19:53:49.011\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mimport_audio_dataset\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mLoading 7442 files to list...\u001b[0m\n",
            "100%|██████████| 7442/7442 [00:08<00:00, 853.94it/s] \n",
            "\u001b[32m2024-03-19 19:53:57.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mimport_audio_dataset\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1mLoading 7442 files to awkward array...\u001b[0m\n",
            "100%|██████████| 7442/7442 [05:55<00:00, 20.92it/s]\n"
          ]
        }
      ],
      "source": [
        "Xr, srr = import_audio_dataset(\"./ravdess/\", \".wav\")\n",
        "Xc, src = import_audio_dataset(\"./crema/\", \".wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "Xr = pad_awkward_array(Xr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "lnPRyaFEu8OG"
      },
      "outputs": [],
      "source": [
        "Xc = pad_awkward_array(Xc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "Xc = torch.tensor(Xc.to_numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "67tLRs07VmXa"
      },
      "outputs": [],
      "source": [
        "Xr = torch.tensor(Xr.to_numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "sKVwCRx4V0ML"
      },
      "outputs": [],
      "source": [
        "Xr = downsample_tensor(Xr, 48000, 16000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "5gnc-4wvWBuk"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-03-19 20:46:36.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36maudio_tokenizer\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mToken size 440; Padded length 102080\n",
            ";Number of tokens 232\u001b[0m\n",
            "\u001b[32m2024-03-19 20:46:37.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36maudio_tokenizer\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mToken size 440; Padded length 80080\n",
            ";Number of tokens 182\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "Xr = audio_tokenizer(Xr, 16000, 27.5)\n",
        "Xc = audio_tokenizer(Xc, 16000, 27.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "u1JZmPpTTQZp"
      },
      "outputs": [],
      "source": [
        "Yr = encode_file_names(get_file_list(\"./ravdess/\", \".wav\"), \"ravdess\")\n",
        "Yc = encode_file_names(get_file_list(\"./crema/\", \".wav\"), \"crema\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "1OoqBmmjTcmk"
      },
      "outputs": [],
      "source": [
        "Yr_sorted_actor = Yr.sort_values(by=[\"actor\", \"filename\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Cf6Z01VVPsHR"
      },
      "outputs": [],
      "source": [
        "Yr_train = Yr_sorted_actor[Yr_sorted_actor.actor.astype(int) < 19]\n",
        "Yr_vt = Yr_sorted_actor[Yr_sorted_actor.actor.astype(int) >= 19]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "voWyl27VULvB"
      },
      "outputs": [],
      "source": [
        "Yr_val = Yr_vt[Yr_vt.actor.astype(int)<22]\n",
        "Yr_test = Yr_vt[Yr_vt.actor.astype(int)>=22]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "7kKF-mb3UZTR"
      },
      "outputs": [],
      "source": [
        "idx_train = list(Yr_train.index)\n",
        "idx_val = list(Yr_val.index)\n",
        "idx_test = list(Yr_test.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "rpldict = dict(zip(sorted(np.unique(Yr_train.emotion)), range(0,8)))\n",
        "y_train = Yr_train.emotion.replace(rpldict).values\n",
        "y_val = Yr_val.emotion.replace(rpldict).values\n",
        "y_test = Yr_test.emotion.replace(rpldict).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "CNes7G1hU9Z_"
      },
      "outputs": [],
      "source": [
        "Xr_train = Xr[idx_train]\n",
        "Xr_val = Xr[idx_val]\n",
        "Xr_test = Xr[idx_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "PzquF2CUsId7"
      },
      "outputs": [],
      "source": [
        "Yc_sorted_actor = Yc.sort_values(by=[\"actor\", \"filename\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "qjIyzeDJsL-V"
      },
      "outputs": [],
      "source": [
        "Yc_train = Yc_sorted_actor[Yc_sorted_actor.actor.astype(int) < 72]\n",
        "Yc_val = Yc_sorted_actor[Yc_sorted_actor.actor.astype(int) >= 72]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "__yxT7Pwsbkj"
      },
      "outputs": [],
      "source": [
        "idx_train = list(Yc_train.index)\n",
        "idx_val = list(Yc_val.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "JXa3MnnIsfm9"
      },
      "outputs": [],
      "source": [
        "Xc_train = Xc[idx_train]\n",
        "Xc_val = Xc[idx_val]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "rpldict = dict(zip(sorted(np.unique(Yc_train.emotion)), range(0,6)))\n",
        "yc_train = Yc_train.emotion.replace(rpldict).values\n",
        "yc_val = Yc_val.emotion.replace(rpldict).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "tOEunjFtsk5g"
      },
      "outputs": [],
      "source": [
        "torch.save(Xr_train, \"./Xr_train.pt\")\n",
        "torch.save(Xr_test, \"./Xr_test.pt\")\n",
        "torch.save(Xr_val, \"./Xr_val.pt\")\n",
        "\n",
        "torch.save(Xc_train, \"./Xc_train.pt\")\n",
        "torch.save(Xc_val, \"./Xc_val.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "FsxIoRX1vDQF"
      },
      "outputs": [],
      "source": [
        "torch.save(torch.tensor(y_train), \"./y_train.pt\")\n",
        "torch.save(torch.tensor(y_test), \"./y_test.pt\")\n",
        "torch.save(torch.tensor(y_val), \"./y_val.pt\")\n",
        "\n",
        "torch.save(torch.tensor(yc_train), \"./yc_train.pt\")\n",
        "torch.save(torch.tensor(yc_val), \"./yc_val.pt\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
